## DATABASE
#Turn S3  on
s3="on"
# S3 bucket containing the database
s3_database_dir="s3://bibicloud-db/swissprot/"

# directory containing the database (in the S3 bucket or on the host)
database_dir="/vol/biodb"

# database filename in the database directory
database_file="swissprot"

# download type from S3 ["folder","file","split-fastq"]
db_download_type="file"

## INPUT

# S3 bucket containing the input data
s3_input_dir="s3://dkramer/"

# directory containing the input data (in the S3 bucket or on the host)
input_dir="/vol/spool"

# input filename in the input directory
input_file="prot_sequence.fasta"

# download type from S3 ["folder","file","split-fastq"]
input_download_type="folder"

## OUTPUT

# output directory on the host
output_dir="/vol/spool"

## MISC

# S3 region needed to locate bucket?
s3_region="us-east-1"

# private docker registry address, e.g. "192.168.100.100:5000/"
# leave empty to use Dockerhub
docker_registry=""

# docker image name
docker_image="mzur/blast-pipeline"

# number of tasks created by the cluster engine
num_tasks="2"

# number of nodes/slaves used by the cluster engine
num_nodes="2"

# script to call when fetching the data is finished
# usually only the arguments must be touched
pipeline_script="./docker_run.sh $input_file $num_tasks $database_file $input_dir $database_dir $output_dir $docker_registry$docker_image"